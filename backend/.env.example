# LLM model to use for chat
MODEL_NAME=gemini-2.5-pro
# Show model "thinking" process in the UI
SHOW_MODEL_THINKING=false

# Google Gemini / Vertex AI settings
GOOGLE_CLOUD_PROJECT=tenantfirstaid
# Fill with your own path (see README.md Local Development/Prerequisites for details)
GOOGLE_APPLICATION_CREDENTIALS=/home/<USERNAME>/.config/gcloud/application_default_credentials.json

# Google Vertex RAG settings
GOOGLE_CLOUD_LOCATION=global
# Fill with your own datastore ID or the TFA one
VERTEX_AI_DATASTORE=<DATASTORE_ID>
# List available datastores:
#   % cd backend/scripts
#   % uv run ./vertex_ai_list_datastores.py | grep -e "^name:"
# VERTEX_AI_DATASTORE=tenantfirstaid-corpora_1758844059585  # used in production
# VERTEX_AI_DATASTORE=tenantfirstaid_1750282258079  # pre-production/partial

# LangChain/LangSmith API keys and tracing settings
LANGSMITH_API_KEY=lsv2_pt_some-example-key_XXXXXXXXXXXXXXXXXXXXXX
LANGSMITH_TRACING=true
LANGCHAIN_TRACING_V2=true               # Enable detailed tracing

# SMTP setup
#MAIL_SERVER="smtp.service.com"
#MAIL_PORT=587
#SENDER_EMAIL="your_email@gmail.com"
#APP_PASSWORD="app_specific_password"
#RECIPIENT_EMAIL="email_of_recipient@email.com"

# Set to "dev" to show detailed debug output
ENV=dev
